"""
æœç´¢å·¥å…·å¯¹æ¯”æµ‹è¯•
===================
å¯¹æ¯” Tavily å’Œ Auto Search Tool çš„æ€§èƒ½å’Œç»“æœè´¨é‡
"""

import os
import sys
import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Literal

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æœç´¢å·¥å…·
from tavily import TavilyClient

# ç›´æ¥å¯¼å…¥ auto_search_tool æ¨¡å—ï¼Œé¿å…é€šè¿‡ deepagents
import importlib.util
auto_search_spec = importlib.util.spec_from_file_location(
    "auto_search_tool",
    str(project_root / "src" / "deepagents" / "tools" / "auto_search_tool.py")
)
auto_search_module = importlib.util.module_from_spec(auto_search_spec)
auto_search_spec.loader.exec_module(auto_search_module)
create_auto_search_tool = auto_search_module.create_auto_search_tool


class SearchComparison:
    """æœç´¢å·¥å…·å¯¹æ¯”æµ‹è¯•ç±»"""

    def __init__(self):
        # åˆå§‹åŒ– Tavily
        self.tavily_client = TavilyClient(api_key=os.environ["TAVILY_KEY"])

        # åˆå§‹åŒ– Auto Search Tool
        self.auto_search = create_auto_search_tool(
            brightdata_api_key=os.environ["BRIGHTDATA_API_KEY"],
            firecrawl_api_key=os.environ.get("FIRECRAWL_API_KEY"),
            auto_fetch_limit=5,
            enable_smart_extraction=True,
            confidence_threshold=0.7
        )

        print("âœ… æœç´¢å·¥å…·åˆå§‹åŒ–å®Œæˆ")
        print(f"   - Tavily API Key: {os.environ['TAVILY_KEY'][:20]}...")
        print(f"   - BrightData API Key: {os.environ['BRIGHTDATA_API_KEY'][:20]}...")

    def test_tavily(self, query: str, max_results: int = 5):
        """æµ‹è¯• Tavily æœç´¢"""
        print(f"\n{'='*60}")
        print(f"ğŸ” Tavily æœç´¢: {query}")
        print(f"{'='*60}")

        start_time = datetime.now()

        try:
            result = self.tavily_client.search(
                query=query,
                max_results=max_results,
                include_raw_content=False,
                topic="general"
            )

            elapsed = (datetime.now() - start_time).total_seconds()

            print(f"\nâ±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
            print(f"ğŸ“Š ç»“æœæ•°é‡: {len(result.get('results', []))}")

            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            for i, item in enumerate(result.get('results', [])[:3], 1):
                print(f"\n[{i}] {item.get('title', 'No title')}")
                print(f"    URL: {item.get('url', 'No URL')}")
                print(f"    Score: {item.get('score', 0):.3f}")
                snippet = item.get('content', '')[:150]
                print(f"    Snippet: {snippet}...")

            return {
                'success': True,
                'tool': 'tavily',
                'query': query,
                'elapsed': elapsed,
                'results_count': len(result.get('results', [])),
                'results': result.get('results', []),
                'raw_response': result
            }

        except Exception as e:
            elapsed = (datetime.now() - start_time).total_seconds()
            print(f"\nâŒ Tavily æœç´¢å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'tool': 'tavily',
                'query': query,
                'error': str(e),
                'elapsed': elapsed
            }

    async def test_auto_search(self, query: str, num_results: int = 5, mode: str = "full"):
        """æµ‹è¯• Auto Search Tool"""
        print(f"\n{'='*60}")
        print(f"ğŸ” Auto Search ({mode} æ¨¡å¼): {query}")
        print(f"{'='*60}")

        start_time = datetime.now()

        try:
            # ä½¿ç”¨ <search> æ ‡ç­¾åŒ…è£…æŸ¥è¯¢
            formatted_query = f"<search>{query}</search>"

            result = await self.auto_search.ainvoke({
                "query": formatted_query,
                "num_results": num_results,
                "mode": mode
            })

            elapsed = (datetime.now() - start_time).total_seconds()

            print(f"\nâ±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
            print(f"ğŸ“Š ç»“æœæ•°é‡: {len(result.get('results', []))}")

            stats = result.get('statistics', {})
            print(f"ğŸ“ˆ ç»Ÿè®¡:")
            print(f"   - æ€»ç»“æœ: {stats.get('total_results', 0)}")
            print(f"   - è‡ªåŠ¨æŠ“å–: {stats.get('auto_fetched', 0)}")
            print(f"   - æŠ“å–æˆåŠŸ: {stats.get('fetch_success', 0)}")
            print(f"   - PDFæ–‡æ¡£: {stats.get('pdf_count', 0)}")

            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            for i, item in enumerate(result.get('results', [])[:3], 1):
                print(f"\n[{i}] {item.get('title', 'No title')}")
                print(f"    URL: {item.get('url', 'No URL')}")
                print(f"    Position: {item.get('position', 0)}")

                if item.get('fetch_success'):
                    print(f"    âœ… å†…å®¹æŠ“å–æˆåŠŸ")
                    print(f"       - é•¿åº¦: {item.get('content_length', 0)} å­—ç¬¦")
                    print(f"       - Tokens: {item.get('estimated_tokens', 0)}")
                    print(f"       - æ–¹æ³•: {item.get('extraction_method', 'unknown')}")
                    print(f"       - PDF: {'æ˜¯' if item.get('is_pdf') else 'å¦'}")

                    # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                    content = item.get('content', '')
                    preview = content[:150] + '...' if len(content) > 150 else content
                    print(f"       - é¢„è§ˆ: {preview}")
                else:
                    print(f"    âŒ å†…å®¹æŠ“å–å¤±è´¥: {item.get('fetch_error', 'Unknown')}")
                    snippet = item.get('snippet', '')[:150]
                    print(f"       - Snippet: {snippet}...")

            return {
                'success': True,
                'tool': 'auto_search',
                'query': query,
                'mode': mode,
                'elapsed': elapsed,
                'results_count': len(result.get('results', [])),
                'statistics': stats,
                'results': result.get('results', []),
                'raw_response': result
            }

        except Exception as e:
            elapsed = (datetime.now() - start_time).total_seconds()
            print(f"\nâŒ Auto Search å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'tool': 'auto_search',
                'query': query,
                'mode': mode,
                'error': str(e),
                'elapsed': elapsed
            }

    async def test_parallel_search(self, queries: list[str], num_results: int = 10):
        """æµ‹è¯•å¹¶è¡Œæœç´¢åŠŸèƒ½ï¼ˆAuto Search ç‹¬æœ‰ï¼‰"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ Auto Search å¹¶è¡Œæœç´¢æµ‹è¯•")
        print(f"{'='*60}")

        # æ„å»ºå¹¶è¡ŒæŸ¥è¯¢
        parallel_query = "<search>" + "|".join(queries) + "</search>"
        print(f"æŸ¥è¯¢: {parallel_query}")

        start_time = datetime.now()

        try:
            result = await self.auto_search.ainvoke({
                "query": parallel_query,
                "num_results": num_results,
                "mode": "light"  # å¹¶è¡Œæœç´¢ç”¨ light æ¨¡å¼æ›´å¿«
            })

            elapsed = (datetime.now() - start_time).total_seconds()

            print(f"\nâ±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
            print(f"ğŸ”„ å¹¶è¡ŒæŸ¥è¯¢: {len(queries)} ä¸ª")

            stats = result.get('statistics', {})
            print(f"ğŸ“ˆ ç»Ÿè®¡:")
            print(f"   - æ€»æŸ¥è¯¢: {stats.get('total_queries', 0)}")
            print(f"   - æˆåŠŸæŸ¥è¯¢: {stats.get('successful_queries', 0)}")
            print(f"   - æ€»ç»“æœ: {stats.get('total_results', 0)}")

            # æ˜¾ç¤ºæ¯ä¸ªæŸ¥è¯¢çš„ç»“æœ
            for detail in stats.get('query_details', []):
                print(f"\n   æŸ¥è¯¢ [{detail['query_index']}]: {detail['query']}")
                print(f"      - æˆåŠŸ: {'âœ…' if detail['success'] else 'âŒ'}")
                if detail['success']:
                    print(f"      - ç»“æœæ•°: {detail.get('results_count', 0)}")
                else:
                    print(f"      - é”™è¯¯: {detail.get('error', 'Unknown')}")

            return {
                'success': True,
                'tool': 'auto_search_parallel',
                'queries': queries,
                'elapsed': elapsed,
                'statistics': stats,
                'raw_response': result
            }

        except Exception as e:
            elapsed = (datetime.now() - start_time).total_seconds()
            print(f"\nâŒ å¹¶è¡Œæœç´¢å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'tool': 'auto_search_parallel',
                'queries': queries,
                'error': str(e),
                'elapsed': elapsed
            }

    def compare_results(self, tavily_result, auto_search_result):
        """å¯¹æ¯”ä¸¤ä¸ªå·¥å…·çš„ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ç»“æœå¯¹æ¯”")
        print(f"{'='*60}")

        if tavily_result['success'] and auto_search_result['success']:
            print(f"\nâ±ï¸  æ€§èƒ½å¯¹æ¯”:")
            print(f"   Tavily:      {tavily_result['elapsed']:.2f}ç§’")
            print(f"   Auto Search: {auto_search_result['elapsed']:.2f}ç§’")
            print(f"   å·®å¼‚:        {auto_search_result['elapsed'] - tavily_result['elapsed']:.2f}ç§’")

            print(f"\nğŸ“Š ç»“æœæ•°é‡:")
            print(f"   Tavily:      {tavily_result['results_count']} ä¸ª")
            print(f"   Auto Search: {auto_search_result['results_count']} ä¸ª")

            print(f"\nâœ¨ åŠŸèƒ½å¯¹æ¯”:")
            print(f"   PDF è§£æ:")
            print(f"      Tavily:      âŒ")
            print(f"      Auto Search: âœ… ({auto_search_result['statistics'].get('pdf_count', 0)} ä¸ª)")

            print(f"   å®Œæ•´å†…å®¹æŠ“å–:")
            print(f"      Tavily:      âŒ (ä»… snippet)")
            print(f"      Auto Search: âœ… ({auto_search_result['statistics'].get('fetch_success', 0)}/{auto_search_result['statistics'].get('auto_fetched', 0)} æˆåŠŸ)")

            print(f"   å¹¶è¡Œæœç´¢:")
            print(f"      Tavily:      âŒ")
            print(f"      Auto Search: âœ…")

            # URL é‡å åˆ†æ
            tavily_urls = set(r.get('url', '') for r in tavily_result['results'])
            auto_urls = set(r.get('url', '') for r in auto_search_result['results'])
            overlap = tavily_urls & auto_urls

            print(f"\nğŸ”— URL é‡å :")
            print(f"   å…±åŒ URL: {len(overlap)} ä¸ª")
            if overlap:
                print(f"   é‡å ç‡: {len(overlap)/min(len(tavily_urls), len(auto_urls))*100:.1f}%")
                print(f"   é‡å  URL:")
                for url in list(overlap)[:3]:
                    print(f"      - {url}")
        else:
            if not tavily_result['success']:
                print(f"\nâŒ Tavily å¤±è´¥: {tavily_result.get('error', 'Unknown')}")
            if not auto_search_result['success']:
                print(f"\nâŒ Auto Search å¤±è´¥: {auto_search_result.get('error', 'Unknown')}")


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print(f"\n{'#'*60}")
    print(f"# æœç´¢å·¥å…·å¯¹æ¯”æµ‹è¯•")
    print(f"# æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'#'*60}")

    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    comparison = SearchComparison()

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "LangGraph architecture and features",
        "RAG optimization techniques 2024",
        "DeepSeek AI model capabilities"
    ]

    # æµ‹è¯• 1: å•ä¸€æŸ¥è¯¢å¯¹æ¯”
    print(f"\n\n{'#'*60}")
    print(f"# æµ‹è¯• 1: å•ä¸€æŸ¥è¯¢å¯¹æ¯”")
    print(f"{'#'*60}")

    query = test_queries[0]

    # Tavily æµ‹è¯•
    tavily_result = comparison.test_tavily(query, max_results=5)

    # Auto Search Light æ¨¡å¼æµ‹è¯•
    auto_light_result = await comparison.test_auto_search(query, num_results=5, mode="light")

    # Auto Search Full æ¨¡å¼æµ‹è¯•
    auto_full_result = await comparison.test_auto_search(query, num_results=5, mode="full")

    # å¯¹æ¯”ç»“æœ
    if tavily_result['success'] and auto_full_result['success']:
        comparison.compare_results(tavily_result, auto_full_result)

    # æµ‹è¯• 2: å¹¶è¡Œæœç´¢ï¼ˆAuto Search ç‹¬æœ‰åŠŸèƒ½ï¼‰
    print(f"\n\n{'#'*60}")
    print(f"# æµ‹è¯• 2: å¹¶è¡Œæœç´¢ (Auto Search ç‹¬æœ‰)")
    print(f"{'#'*60}")

    parallel_queries = test_queries
    parallel_result = await comparison.test_parallel_search(parallel_queries, num_results=12)

    if parallel_result['success']:
        print(f"\nâœ… å¹¶è¡Œæœç´¢æˆåŠŸå®Œæˆ")
        print(f"   ç›¸æ¯”ä¸²è¡Œæ‰§è¡Œ Tavily {len(parallel_queries)} æ¬¡:")
        estimated_tavily_time = tavily_result['elapsed'] * len(parallel_queries)
        time_saved = estimated_tavily_time - parallel_result['elapsed']
        print(f"   ä¼°ç®— Tavily ä¸²è¡Œæ—¶é—´: {estimated_tavily_time:.2f}ç§’")
        print(f"   Auto Search å¹¶è¡Œæ—¶é—´: {parallel_result['elapsed']:.2f}ç§’")
        print(f"   èŠ‚çœæ—¶é—´: {time_saved:.2f}ç§’ ({time_saved/estimated_tavily_time*100:.1f}%)")

    # æµ‹è¯• 3: å†…å®¹è´¨é‡å¯¹æ¯”
    print(f"\n\n{'#'*60}")
    print(f"# æµ‹è¯• 3: å†…å®¹è´¨é‡å¯¹æ¯”")
    print(f"{'#'*60}")

    if tavily_result['success'] and auto_full_result['success']:
        print(f"\nTavily å†…å®¹ç¤ºä¾‹ (ç¬¬1ä¸ªç»“æœ):")
        tavily_first = tavily_result['results'][0] if tavily_result['results'] else {}
        print(f"   Title: {tavily_first.get('title', 'N/A')[:60]}...")
        print(f"   Content: {tavily_first.get('content', 'N/A')[:200]}...")
        print(f"   Content Length: {len(tavily_first.get('content', ''))} å­—ç¬¦")

        print(f"\nAuto Search å†…å®¹ç¤ºä¾‹ (ç¬¬1ä¸ªç»“æœ):")
        auto_first = auto_full_result['results'][0] if auto_full_result['results'] else {}
        print(f"   Title: {auto_first.get('title', 'N/A')[:60]}...")
        if auto_first.get('fetch_success'):
            content = auto_first.get('content', 'N/A')
            print(f"   Content: {content[:200]}...")
            print(f"   Content Length: {len(content)} å­—ç¬¦")
            print(f"   Estimated Tokens: {auto_first.get('estimated_tokens', 0)}")
            print(f"   Extraction Method: {auto_first.get('extraction_method', 'unknown')}")
        else:
            print(f"   âŒ æŠ“å–å¤±è´¥")

    # ä¿å­˜æµ‹è¯•ç»“æœ
    results_dir = project_root / "tests" / "results"
    results_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = results_dir / f"search_comparison_{timestamp}.json"

    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': timestamp,
            'test_queries': test_queries,
            'tavily_result': {k: v for k, v in tavily_result.items() if k != 'raw_response'},
            'auto_light_result': {k: v for k, v in auto_light_result.items() if k != 'raw_response'},
            'auto_full_result': {k: v for k, v in auto_full_result.items() if k != 'raw_response'},
            'parallel_result': {k: v for k, v in parallel_result.items() if k != 'raw_response'},
        }, f, indent=2, ensure_ascii=False)

    print(f"\n\n{'#'*60}")
    print(f"# æµ‹è¯•å®Œæˆ")
    print(f"{'#'*60}")
    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

    # æ€»ç»“
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f"   âœ… Tavily: é€Ÿåº¦å¿«ï¼Œé›†æˆç®€å•ï¼Œä½†åŠŸèƒ½æœ‰é™")
    print(f"   âœ… Auto Search (Light): é€Ÿåº¦æ¥è¿‘ Tavilyï¼Œæ”¯æŒæ›´å¤šåŠŸèƒ½")
    print(f"   âœ… Auto Search (Full): æ·±åº¦å†…å®¹æŠ“å–ï¼ŒPDF è§£æï¼Œå®Œå…¨è‡ªä¸»")
    print(f"   ğŸš€ Auto Search (Parallel): ç‹¬æœ‰åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡æ•ˆç‡")

    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"   - å¿«é€Ÿé¢„è§ˆ: ä½¿ç”¨ Tavily æˆ– Auto Search Light æ¨¡å¼")
    print(f"   - æ·±åº¦ç ”ç©¶: ä½¿ç”¨ Auto Search Full æ¨¡å¼")
    print(f"   - å¤šä¸»é¢˜ç ”ç©¶: ä½¿ç”¨ Auto Search å¹¶è¡Œæœç´¢")
    print(f"   - éœ€è¦ PDF: å¿…é¡»ä½¿ç”¨ Auto Search")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
