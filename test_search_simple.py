"""
ç®€åŒ–çš„æœç´¢å·¥å…·å¯¹æ¯”æµ‹è¯•
ç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
"""

import os
import sys
import asyncio
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, "src")

# å¯¼å…¥
from tavily import TavilyClient
from deepagents.auto_search_tool.auto_search_tool import create_auto_search_tool


async def test_comparison():
    """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""

    print("\n" + "="*60)
    print("æœç´¢å·¥å…·å¯¹æ¯”æµ‹è¯•")
    print("="*60)

    # æµ‹è¯•æŸ¥è¯¢
    query = "LangGraph architecture and features 2024"

    # ========== Tavily æµ‹è¯• ==========
    print(f"\n{'#'*60}")
    print("# æµ‹è¯• 1: Tavily")
    print(f"{'#'*60}")
    print(f"æŸ¥è¯¢: {query}")

    tavily_client = TavilyClient(api_key=os.environ["TAVILY_KEY"])

    tavily_start = datetime.now()
    try:
        tavily_result = tavily_client.search(
            query=query,
            max_results=5,
            include_raw_content=False,
            topic="general"
        )
        tavily_elapsed = (datetime.now() - tavily_start).total_seconds()

        print(f"\nâœ… Tavily æˆåŠŸ")
        print(f"   è€—æ—¶: {tavily_elapsed:.2f}ç§’")
        print(f"   ç»“æœæ•°: {len(tavily_result.get('results', []))}")

        for i, item in enumerate(tavily_result.get('results', [])[:3], 1):
            print(f"\n   [{i}] {item.get('title', 'No title')[:60]}...")
            print(f"       URL: {item.get('url', '')[:70]}...")
            print(f"       Score: {item.get('score', 0):.3f}")
            content = item.get('content', '')
            print(f"       Content: {len(content)} å­—ç¬¦")
            print(f"       Preview: {content[:100]}...")

    except Exception as e:
        tavily_elapsed = (datetime.now() - tavily_start).total_seconds()
        print(f"\nâŒ Tavily å¤±è´¥: {str(e)}")
        tavily_result = None

    # ========== Auto Search Light æ¨¡å¼æµ‹è¯• ==========
    print(f"\n{'#'*60}")
    print("# æµ‹è¯• 2: Auto Search (Light æ¨¡å¼)")
    print(f"{'#'*60}")
    print(f"æŸ¥è¯¢: {query}")

    auto_search = create_auto_search_tool(
        brightdata_api_key=os.environ["BRIGHTDATA_API_KEY"],
        auto_fetch_limit=5,
        enable_smart_extraction=True
    )

    auto_light_start = datetime.now()
    try:
        auto_light_result = await auto_search.ainvoke({
            "query": f"<search>{query}</search>",
            "num_results": 5,
            "mode": "light"
        })
        auto_light_elapsed = (datetime.now() - auto_light_start).total_seconds()

        print(f"\nâœ… Auto Search (Light) æˆåŠŸ")
        print(f"   è€—æ—¶: {auto_light_elapsed:.2f}ç§’")
        print(f"   ç»“æœæ•°: {len(auto_light_result.get('results', []))}")

        stats = auto_light_result.get('statistics', {})
        print(f"   ç»Ÿè®¡: {stats}")

        for i, item in enumerate(auto_light_result.get('results', [])[:3], 1):
            print(f"\n   [{i}] {item.get('title', 'No title')[:60]}...")
            print(f"       URL: {item.get('url', '')[:70]}...")
            print(f"       Snippet: {len(item.get('snippet', '') or '')} å­—ç¬¦")
            content = item.get('content', '') or ''
            print(f"       Content: {content[:100]}...")

    except Exception as e:
        auto_light_elapsed = (datetime.now() - auto_light_start).total_seconds()
        print(f"\nâŒ Auto Search (Light) å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        auto_light_result = None

    # ========== Auto Search Full æ¨¡å¼æµ‹è¯• ==========
    print(f"\n{'#'*60}")
    print("# æµ‹è¯• 3: Auto Search (Full æ¨¡å¼)")
    print(f"{'#'*60}")
    print(f"æŸ¥è¯¢: {query}")

    auto_full_start = datetime.now()
    try:
        auto_full_result = await auto_search.ainvoke({
            "query": f"<search>{query}</search>",
            "num_results": 5,
            "mode": "full"
        })
        auto_full_elapsed = (datetime.now() - auto_full_start).total_seconds()

        print(f"\nâœ… Auto Search (Full) æˆåŠŸ")
        print(f"   è€—æ—¶: {auto_full_elapsed:.2f}ç§’")
        print(f"   ç»“æœæ•°: {len(auto_full_result.get('results', []))}")

        stats = auto_full_result.get('statistics', {})
        print(f"   ç»Ÿè®¡:")
        print(f"      - æ€»ç»“æœ: {stats.get('total_results', 0)}")
        print(f"      - è‡ªåŠ¨æŠ“å–: {stats.get('auto_fetched', 0)}")
        print(f"      - æŠ“å–æˆåŠŸ: {stats.get('fetch_success', 0)}")
        print(f"      - PDFæ–‡æ¡£: {stats.get('pdf_count', 0)}")

        for i, item in enumerate(auto_full_result.get('results', [])[:3], 1):
            print(f"\n   [{i}] {item.get('title', 'No title')[:60]}...")
            print(f"       URL: {item.get('url', '')[:70]}...")

            if item.get('fetch_success'):
                print(f"       âœ… å†…å®¹æŠ“å–æˆåŠŸ")
                print(f"          é•¿åº¦: {item.get('content_length', 0)} å­—ç¬¦")
                print(f"          Tokens: {item.get('estimated_tokens', 0)}")
                print(f"          æ–¹æ³•: {item.get('extraction_method', 'unknown')}")
                print(f"          PDF: {'æ˜¯' if item.get('is_pdf') else 'å¦'}")
                content = item.get('content', '')
                print(f"          é¢„è§ˆ: {content[:150]}...")
            else:
                print(f"       âŒ æŠ“å–å¤±è´¥: {item.get('fetch_error', 'Unknown')}")

    except Exception as e:
        auto_full_elapsed = (datetime.now() - auto_full_start).total_seconds()
        print(f"\nâŒ Auto Search (Full) å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        auto_full_result = None

    # ========== å¹¶è¡Œæœç´¢æµ‹è¯• ==========
    print(f"\n{'#'*60}")
    print("# æµ‹è¯• 4: Auto Search å¹¶è¡Œæœç´¢")
    print(f"{'#'*60}")

    parallel_queries = [
        "LangGraph architecture",
        "LangChain agents",
        "RAG optimization 2024"
    ]
    parallel_query = "<search>" + "|".join(parallel_queries) + "</search>"
    print(f"å¹¶è¡ŒæŸ¥è¯¢: {parallel_queries}")

    parallel_start = datetime.now()
    try:
        parallel_result = await auto_search.ainvoke({
            "query": parallel_query,
            "num_results": 12,
            "mode": "light"
        })
        parallel_elapsed = (datetime.now() - parallel_start).total_seconds()

        print(f"\nâœ… å¹¶è¡Œæœç´¢æˆåŠŸ")
        print(f"   è€—æ—¶: {parallel_elapsed:.2f}ç§’")

        stats = parallel_result.get('statistics', {})
        print(f"   ç»Ÿè®¡:")
        print(f"      - æ€»æŸ¥è¯¢: {stats.get('total_queries', 0)}")
        print(f"      - æˆåŠŸæŸ¥è¯¢: {stats.get('successful_queries', 0)}")
        print(f"      - æ€»ç»“æœ: {stats.get('total_results', 0)}")

        for detail in stats.get('query_details', []):
            print(f"\n   [{detail['query_index']}] {detail['query']}")
            print(f"       æˆåŠŸ: {'âœ…' if detail['success'] else 'âŒ'}")
            if detail['success']:
                print(f"       ç»“æœæ•°: {detail.get('results_count', 0)}")

        # è®¡ç®—æ€§èƒ½æå‡
        if tavily_result:
            estimated_serial = tavily_elapsed * len(parallel_queries)
            time_saved = estimated_serial - parallel_elapsed
            print(f"\n   æ€§èƒ½å¯¹æ¯”:")
            print(f"      Tavily ä¸²è¡Œæ—¶é—´ä¼°ç®—: {estimated_serial:.2f}ç§’")
            print(f"      Auto Search å¹¶è¡Œ: {parallel_elapsed:.2f}ç§’")
            print(f"      èŠ‚çœæ—¶é—´: {time_saved:.2f}ç§’ ({time_saved/estimated_serial*100:.1f}%)")

    except Exception as e:
        parallel_elapsed = (datetime.now() - parallel_start).total_seconds()
        print(f"\nâŒ å¹¶è¡Œæœç´¢å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

    # ========== æ€»ç»“å¯¹æ¯” ==========
    print(f"\n{'='*60}")
    print("æ€»ç»“å¯¹æ¯”")
    print(f"{'='*60}")

    if tavily_result and auto_full_result:
        print(f"\nâ±ï¸  æ€§èƒ½:")
        print(f"   Tavily:            {tavily_elapsed:.2f}ç§’")
        print(f"   Auto Search Light: {auto_light_elapsed:.2f}ç§’")
        print(f"   Auto Search Full:  {auto_full_elapsed:.2f}ç§’")

        print(f"\nâœ¨ åŠŸèƒ½:")
        print(f"   PDF æ”¯æŒ:")
        print(f"      Tavily:      âŒ")
        print(f"      Auto Search: âœ… ({auto_full_result['statistics'].get('pdf_count', 0)} ä¸ª)")

        print(f"   å®Œæ•´å†…å®¹:")
        print(f"      Tavily:      âŒ (ä»…snippet)")
        print(f"      Auto Search: âœ… ({auto_full_result['statistics'].get('fetch_success', 0)}/{auto_full_result['statistics'].get('auto_fetched', 0)})")

        print(f"   å¹¶è¡Œæœç´¢:")
        print(f"      Tavily:      âŒ")
        print(f"      Auto Search: âœ…")

        print(f"\nğŸ’¡ å»ºè®®:")
        print(f"   - å¿«é€Ÿé¢„è§ˆ: Tavily æˆ– Auto Search Light")
        print(f"   - æ·±åº¦ç ”ç©¶: Auto Search Full")
        print(f"   - å¤šä¸»é¢˜: Auto Search å¹¶è¡Œ")
        print(f"   - PDF æ–‡æ¡£: Auto Search Full")

    print(f"\nâœ… æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(test_comparison())
